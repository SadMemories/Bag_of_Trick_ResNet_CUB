{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dd74f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_val image num: 5994\n",
      "test image num: 5794\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_path = '/datasets/CUB/CUB_200_2011'\n",
    "root_image_path = os.path.join(root_path, 'images')\n",
    "assert os.path.exists(root_image_path), '{} root image path is not exists...'.format(root_image_path)\n",
    "assert os.path.exists(root_path), '{} root path is not exists...'.format(root_path)\n",
    "\n",
    "train_test_path = os.path.join(root_path, 'train_test_split.txt')\n",
    "images_txt_path = os.path.join(root_path, 'images.txt')\n",
    "images_labels_path = os.path.join(root_path, 'image_class_labels.txt')\n",
    "classes_txt_path = os.path.join(root_path, 'classes.txt')\n",
    "assert os.path.exists(train_test_path), '{} train_test_split.txt path is not exists...'.format(train_test_path)\n",
    "assert os.path.exists(images_txt_path), '{} image path is not exists...'.format(images_txt_path)\n",
    "assert os.path.exists(images_labels_path), '{} image_class_labels.txt path is not exists...'.format(images_labels_path)\n",
    "assert os.path.exists(classes_txt_path), '{} classes.txt path is not exists...'.format(classes_txt_path)\n",
    "\n",
    "train_val_id = []\n",
    "test_id = []\n",
    "\n",
    "with open(train_test_path) as f:\n",
    "    for line in f:\n",
    "        image_id, is_train = line.split()\n",
    "        if int(is_train) == 1:\n",
    "            train_val_id.append(image_id)\n",
    "        else:\n",
    "            test_id.append(image_id)\n",
    "\n",
    "images_path = {}\n",
    "labels_dict = {}\n",
    "with open(images_txt_path) as f:\n",
    "    for line in f:\n",
    "        image_id, file_path = line.split()\n",
    "        images_path[image_id] = file_path\n",
    "with open(images_labels_path) as f:\n",
    "    for line in f:\n",
    "        image_id, label = line.split()\n",
    "        labels_dict[image_id] = label\n",
    "\n",
    "train_image_path = []\n",
    "train_label = []\n",
    "test_image_path = []\n",
    "test_label = []\n",
    "for idx in train_val_id:\n",
    "    train_image_path.append(images_path[idx])\n",
    "    train_label.append(int(labels_dict[idx]) - 1)\n",
    "for idx in test_id:\n",
    "    test_image_path.append(images_path[idx])\n",
    "    test_label.append(int(labels_dict[idx]) - 1)\n",
    "\n",
    "print('train_val image num: {}'.format(len(train_image_path)))\n",
    "print('test image num: {}'.format(len(test_image_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74ed3095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_mean_std(dataset):\n",
    "    \n",
    "    mean_b = 0.0\n",
    "    mean_g = 0.0\n",
    "    mean_r = 0.0\n",
    "    \n",
    "    for img, _ in dataset:\n",
    "        img = np.array(img)\n",
    "        mean_b += np.mean(img[:, :, 0])\n",
    "        mean_g += np.mean(img[:, :, 1])\n",
    "        mean_r += np.mean(img[:, :, 2])\n",
    "    \n",
    "    mean_b /= len(dataset)\n",
    "    mean_g /= len(dataset)\n",
    "    mean_r /= len(dataset)\n",
    "    \n",
    "    diff_b = 0.0\n",
    "    diff_g = 0.0\n",
    "    diff_r = 0.0\n",
    "    N = 0\n",
    "    \n",
    "    for img, _ in dataset:\n",
    "        img = np.array(img)\n",
    "        diff_b += np.sum(np.power(img[:, :, 0]-mean_b, 2))\n",
    "        diff_g += np.sum(np.power(img[:, :, 1]-mean_g, 2))\n",
    "        diff_r += np.sum(np.power(img[:, :, 2]-mean_r, 2))\n",
    "        \n",
    "        N += np.prod(img[:, :, 0].shape)\n",
    "    \n",
    "    std_r = np.sqrt(diff_r / N)\n",
    "    std_g = np.sqrt(diff_g / N)\n",
    "    std_b = np.sqrt(diff_b / N)\n",
    "    \n",
    "    mean = [mean_r / 255.0, mean_g / 255.0, mean_b / 255.0]\n",
    "    std = [std_r / 255.0, std_g / 255.0, std_b / 255]\n",
    "    return mean, std\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d0d24c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean: [0.4856074889829789, 0.49941621333172476, 0.43237721533416357]\n",
      " train std: [0.23210242423464963, 0.22770540127125152, 0.2665100731524232]\n",
      "\n",
      "test mean: [0.48621705603298476, 0.4998155767200096, 0.43114317679080444]\n",
      " test std: [0.23264259781393923, 0.2278108523010932, 0.26667242411915676]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dataset import CUB_dataset\n",
    "\n",
    "train_dataset = CUB_dataset(root_image_path, train_image_path, train_label)\n",
    "test_dataset = CUB_dataset(root_image_path, test_image_path, test_label)\n",
    "\n",
    "train_mean, train_std = compute_mean_std(train_dataset)\n",
    "print('train mean: {}\\n train std: {}\\n'.format(train_mean, train_std))\n",
    "test_mean, test_std = compute_mean_std(test_dataset)\n",
    "print('test mean: {}\\n test std: {}\\n'.format(test_mean, test_std))\n",
    "\n",
    "'''\n",
    "bgr:\n",
    "train mean: [0.4856074889829789, 0.49941621333172476, 0.43237721533416357]\n",
    " train std: [0.23210242423464963, 0.22770540127125152, 0.2665100731524232]\n",
    "\n",
    "bgr:\n",
    "test mean: [0.48621705603298476, 0.4998155767200096, 0.43114317679080444]\n",
    " test std: [0.23264259781393923, 0.2278108523010932, 0.26667242411915676]\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
